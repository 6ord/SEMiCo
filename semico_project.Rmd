---
title: "semico"
author: "Jake Daniels"
date: "October 1, 2018"
output: html_document
---

```{r}
library(tidyverse)
library(rtweet)
library(tidytext)
library(wordcloud2)
data(stop_words)
``` 

```{r}
#insert your own tokens
create_token(app = Sys.getenv("TWITTER_APP"),
  consumer_key = Sys.getenv("TWITTER_CONSUMER_KEY"),
  consumer_secret = Sys.getenv("TWITTER_CONSUMER_SECRET"))
```

WordCloud
```{r}
ryePallete <- c('#1C5F9B', '#C1138A', '#2E1D3B', '#FCC210')

wc <- function(x) {
wordcloud2(x, size=0.7, color=rep_len(ryePallete, nrow(x)))
  save.image(paste0(local_trends[i,]$trend,".png"))
}
```

Top 5 Trends
```{r}
local_trends <- get_trends("toronto") %>%
  arrange(desc(tweet_volume)) %>%
  select(trend) %>%
  head(5) 
```

Getting Trend Datas
```{r}
tweet_funct <- function(x){
search_tweets(x,  n = 2000, include_rts = FALSE,  lang = "en", type="recent", retryonratelimit = F)
}
library(purrr)
lt <- map_dfr(local_trends$trend, tweet_funct, .id	= "trend")
#lt <- map_df(local_trends$trend, search_tweets)

for(i in 1:5) 
lt[which(lt$trend==i),]$trend <- local_trends[i,]$trend
```

Visual #1
```{r}
gg<-function(graph){
my_title <- paste("Online Discussion Surrounding", local_trends[i,]$trend)
my_subtitle <- paste("based on", 2000, "recent tweets")
  ggplot(data=graph,aes(x = reorder(word, n), y = n, fill = "blue")) + 
    geom_bar(show.legend = F, stat = "identity", width = 0.8) +
    scale_fill_brewer() + 
    labs(title = my_title, subtitle = my_subtitle, y = "Number of Mentions", x = NULL) +
    coord_flip() +
    theme_classic() +
    theme(plot.title=element_text(family='', face='bold', size=16))
  ggsave(paste0(local_trends[i,]$trend,".png"), path="/Users/jakedaniels/SEMiCo_proj")
}
```

# create a sequence of final functions to work through, sample(gg,wc,last) ?
```{r}
for(i in 1:5)
print(lt %>%
  filter(trend == local_trends[i,]$trend) %>%
  unnest_tokens(word, text) %>%  
  anti_join(stop_words) %>%
  count(word, sort = T) %>% 
  filter(!word %in% c('t.co', tolower(local_trends[i,]$trend), str_replace(local_trends[i,]$trend, "#", ""), str_extract(pattern = "[a-z]+",tolower(local_trends[i,]$trend)), str_extract(pattern = "[a-z]+$",tolower(local_trends[1,]$trend)), 'https', 'amp', 1:10)) %>%
  arrange(desc(n)) %>%
  head(20) %>%
  gg())

# lemma
# sample(c(gg,wc),1)
```

# CHANGE TOKEN TO SEMICO
```{r}
library(twitteR)
library(httr)
setup_twitter_oauth(consumer_key = Sys.getenv("TWITTER_CONSUMER_KEY"), consumer_secret =Sys.getenv("TWITTER_CONSUMER_SECRET"), access_token = "951665733859233792-RuDfOTRGxagpFfVR3bs3zyRRctbGCEP", access_secret = "qh5ORSTqUMD99ukSRmsXLzMJfDiuLvZuRPkUxd9blooLs")
```

```{r}
for(i in 1:5)
tweet(text = paste(local_trends[i,]$trend,"was trending! Here is our summary:"), mediaPath = paste0("~/semico/", local_trends[i,]$trend, ".png"))

#different captions 

sample(c("has been popular!","was trending!"),1)

```

```{r}
#top 6 trends - one big pic

bing <- get_sentiments("bing")
sent <- function(x) {
  print(
    x %>%
  unnest_tokens(word, text) %>%  
  inner_join(bing) %>%
  group_by(trend) %>%
  count(word, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
  )
}
local_sentiment <- sent(lt)

ggplot(local_sentiment, aes(index, sentiment,fill=trend)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~trend, ncol = 2, scales = "free_x")
```
```{r}
local_sent_count <- lt %>%
  unnest_tokens(word, text) %>%  
  inner_join(bing) %>%
  anti_join(stop_words) %>%
  group_by(trend) %>%
  count(word, sentiment, sort =T) 

for(i in 1:5)
local_sent_count_1 <- local_sent_count %>%
  filter(n > 25) %>%
  filter(!word %in% c('t.co', tolower(local_trends[i,]$trend), str_replace(local_trends[i,]$trend, "#", ""), str_extract(pattern = "[a-z]+",tolower(local_trends[i,]$trend)), str_extract(pattern = "[a-z]+$",tolower(local_trends[i,]$trend)), 'https', 'amp', 1:10))

local_sent_count_1
  group_by(trend) %>%
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  facet_wrap(~trend, scales = "free") +
  geom_col() +
  coord_flip() +
  labs(y = "Contribution to sentiment")

# lemma, #more stop_words, fix edits
```