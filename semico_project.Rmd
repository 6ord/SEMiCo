---
title: "semico"
author: "Jake Daniels"
date: "October 1, 2018"
output: html_document
---

```{r}
library(tidyverse)
library(rtweet)
library(tidytext)
library(wordcloud2)
data(stop_words)
``` 

```{r}
#insert your own tokens
create_token(app = Sys.getenv("TWITTER_APP"),
  consumer_key = Sys.getenv("TWITTER_CONSUMER_KEY"),
  consumer_secret = Sys.getenv("TWITTER_CONSUMER_SECRET"))
```

Token Scrape
```{r}
# get the tweets
rtr <- search_tweets("#RoadToRyerson", n = 2000, include_rts = FALSE)
```

```{r}
rtrTable <- rtr %>%
  unnest_tokens(word, text) %>%  #Unnest the words - code via Tidy Text
  anti_join(stop_words) %>%  #remove stop words
  count(word, sort = T) %>% #do a word count
  filter(!word %in% c('t.co', 'https', 'roadtoryerson', 'amp', 'ryersonu', 'ryerson', 'ryersonsa', 'ryersonfcs', 'student', 1:10))
rtrTable
```

WordCloud
```{r}
ryePallete <- c('#1C5F9B', '#C1138A', '#2E1D3B', '#FCC210')

wc <- function(x) {
wordcloud2(x, size=0.7, color=rep_len(ryePallete, nrow(x)))
  save.image(paste0(local_trends[i,]$trend,".png"))
}
```


Top 5 Trends
```{r}
local_trends <- get_trends("toronto") %>%
  arrange(desc(tweet_volume)) %>%
  select(trend) %>%
  head(5) 
```

Getting Trend Datas
```{r}
tweet_funct <- function(x){
search_tweets(x,  n = 2000, include_rts = FALSE,  lang = "en", type="recent", retryonratelimit = F)
}
library(purrr)
lt <- map_dfr(local_trends$trend, tweet_funct, .id	= "trend")
#lt <- map_df(local_trends$trend, search_tweets)

for(i in 1:5) 
lt[which(lt$trend==i),]$trend <- local_trends[i,]$trend
```

Visual #1
```{r}
gg<-function(graph){
my_title <- paste("Online Discussion Surrounding", local_trends[i,]$trend)
my_subtitle <- paste("based on", 2000, "recent tweets")
  ggplot(data=graph,aes(x = reorder(word, n), y = n, fill = "blue")) + 
    geom_bar(show.legend = F, stat = "identity", width = 0.8) +
    scale_fill_brewer() + 
    labs(title = my_title, subtitle = my_subtitle, y = "Number of Mentions", x = NULL) +
    coord_flip() +
    theme_classic() +
    theme(plot.title=element_text(family='', face='bold', size=16))
  ggsave(paste0(local_trends[i,]$trend,".png"), path="C:/Users/Jake/Documents/semico")
}
```

# create a sequence of final functions to work through, sample(gg,wc,last) ?
```{r}
for(i in 1:5)
print(lt %>%
  filter(trend == local_trends[i,]$trend) %>%
  unnest_tokens(word, text) %>%  #Unnest the words - code via Tidy Text
  anti_join(stop_words) %>%  #remove stop words
  count(word, sort = T) %>% #do a word count
  filter(!word %in% c('t.co', local_trends[i,]$trend,'https', 'amp', 1:10)) %>%
  arrange(desc(n)) %>%
  head(20) %>%
  gg())

#sample(c(gg,wc),1)
```

# CHANGE TOKEN TO SEMICO
```{r}
library(twitteR)
library(httr)
setup_twitter_oauth(consumer_key = Sys.getenv("TWITTER_CONSUMER_KEY"), consumer_secret =Sys.getenv("TWITTER_CONSUMER_SECRET"), access_token = "951665733859233792-RuDfOTRGxagpFfVR3bs3zyRRctbGCEP", access_secret = "qh5ORSTqUMD99ukSRmsXLzMJfDiuLvZuRPkUxd9blooLs")
```

```{r}
for(i in 1:5)
tweet(text = paste(local_trends[i,]$trend,"was trending! Here is our summary:"), mediaPath = paste0("~/semico/", local_trends[i,]$trend, ".png"))


```